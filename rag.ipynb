{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 1/1 [00:00<00:00, 13.96it/s]\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "5"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from dotenv import load_dotenv\n",
                "from haystack import Pipeline\n",
                "from haystack.components.builders import ChatPromptBuilder\n",
                "from haystack.components.converters import TextFileToDocument\n",
                "from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder\n",
                "from haystack.components.generators.chat import OpenAIChatGenerator\n",
                "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
                "from haystack.dataclasses import ChatMessage\n",
                "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
                "from haystack.utils import Secret\n",
                "from pathlib import Path\n",
                "\n",
                "# Initialize document store\n",
                "document_store = InMemoryDocumentStore()\n",
                "\n",
                "# Load files and convert to documents\n",
                "files = [f for f in Path(\"./example_data\").iterdir() if f.is_file()]\n",
                "converter = TextFileToDocument()\n",
                "docs = converter.run(sources=files)['documents']\n",
                "\n",
                "# Write documents to the store\n",
                "doc_embedder = SentenceTransformersDocumentEmbedder(\n",
                "    model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
                "doc_embedder.warm_up()\n",
                "\n",
                "docs_with_embeddings = doc_embedder.run(docs)\n",
                "document_store.write_documents(docs_with_embeddings[\"documents\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.77it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'llm': {'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='Eir uses the following financial tools:\\n\\n1. **Visma** for payroll and bookkeeping.\\n2. **Tripletex** for invoicing and expense handling.')], _name=None, _meta={'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 34, 'prompt_tokens': 4506, 'total_tokens': 4540, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=4352)}})]}}\n"
                    ]
                }
            ],
            "source": [
                "load_dotenv()\n",
                "# Define the parts of the pipeline\n",
                "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
                "retriever = InMemoryEmbeddingRetriever(document_store)\n",
                "llm = OpenAIChatGenerator(model=\"gpt-4o-mini\", api_key=Secret.from_env_var(\"OPENAI_KEY\"))\n",
                "prompt_builder = ChatPromptBuilder(template=[\n",
                "    ChatMessage.from_user(\"\"\"\n",
                "                          Given the following information, answer the question.\n",
                "\n",
                "                          Context:\n",
                "                          {% for doc in documents %}\n",
                "                            {{ doc.content }}\n",
                "                          {% endfor %}\n",
                "\n",
                "                          Question: {{ question }}\n",
                "                          Answer:\n",
                "                          \"\"\")\n",
                "])\n",
                "\n",
                "# Create a pipeline\n",
                "pipe = Pipeline()\n",
                "\n",
                "pipe.add_component(\"text_embedder\", text_embedder)\n",
                "pipe.add_component(\"retriever\", retriever)\n",
                "pipe.add_component(\"llm\", llm)\n",
                "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
                "\n",
                "pipe.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
                "pipe.connect(\"retriever\", \"prompt_builder\")\n",
                "pipe.connect(\"prompt_builder.prompt\", \"llm.messages\")\n",
                "\n",
                "# Example query\n",
                "question = \"What kind of financial tools do we use?\"\n",
                "response = pipe.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
                "print(response)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
